# ğŸ“„ğŸ“š Multi-PDF Chatbot using LangChain + Google Gemini Pro

An interactive chatbot that allows users to **upload and query multiple PDFs** using **LangChain** for chunking/retrieval and **Google Gemini Pro** for intelligent answer generation. Designed with a **modular, production-ready architecture** under `src/`.

---

## ğŸ“‚ Project Structure

```
multi-pdf-gemini-chat/
â”œâ”€â”€ app.py                   # Streamlit app UI
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chains.py            # Loads prompt + QA chain
â”‚   â”œâ”€â”€ pdf_utils.py         # Extracts raw text from uploaded PDFs
â”‚   â”œâ”€â”€ chunk_utils.py       # Splits text into chunks using LangChain
â”‚   â”œâ”€â”€ vector_utils.py      # Creates & loads FAISS vector store
â”‚   â””â”€â”€ env_loader.py        # Loads environment variables from .env
â”œâ”€â”€ faiss_index/             # Saved vector DB
â”œâ”€â”€ .env                     # Contains your API key (excluded from repo)
â””â”€â”€ requirements.txt         # Python dependencies
```

---

## ğŸš€ Key Features

- ğŸ“„ Upload and query **multiple PDFs**
- ğŸ§  Uses **LangChain** for context-rich chunking + retrieval
- ğŸ’¬ Uses **Google Gemini Pro** for natural, accurate responses
- ğŸ”— Modular code under `src/` for easy maintenance & reuse
- ğŸ” API key managed securely with `.env` file

---

## ğŸ“Œ Prompt Template (in `chains.py`)

> _â€œIf the answer is not in the provided context, respond with: 'Answer is not available in the context.'â€_

- Custom-crafted to **minimize hallucination**
- Built using `PromptTemplate` + `load_qa_chain` with Gemini Pro

---

## ğŸ’» How to Run Locally

```bash
pip install -r requirements.txt
streamlit run app.py
```

â¡ï¸ Then add your Google API key to a `.env` file:

```env
GOOGLE_API_KEY=your_api_key_here
```

---

## ğŸ§  Use Cases

- ğŸ”¬ Literature review across research PDFs
- ğŸ“ƒ Legal contract analysis
- ğŸ’¼ Financial report Q&A
- ğŸ« Students querying lecture notes

---

## ğŸ¯ For Recruiters / Hiring Managers

- âœ… Showcases **modular GenAI architecture**
- âœ… Integrates **LangChain + Gemini Pro + FAISS** in a clean RAG pipeline
- âœ… Demonstrates practical problem-solving via LLM-based retrieval
- âœ… Portfolio-ready: deployable, readable, and scalable

---

## ğŸ”­ Roadmap

- [x] Modularize all components into `src/` âœ…
- [ ] Add Dockerfile for containerized deployment
- [ ] Add chat history and session memory
- [ ] Add HuggingFace or Streamlit Cloud deployment script
- [ ] Enable multi-user session capability

---

## ğŸ“« Let's Connect

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Aparna-blue?style=flat&logo=linkedin)](https://www.linkedin.com/in/aparna-k-628005167/)
